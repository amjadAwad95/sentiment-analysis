{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T09:29:59.507333Z",
     "start_time": "2025-03-09T09:29:59.496083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import Stemmer\n",
    "import emoji\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "from num2words import num2words\n",
    "from collections import Counter"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:10:55.222066Z",
     "start_time": "2025-03-09T09:10:55.193066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "appos = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"how's\" : \"how is\",\n",
    "    \"i'd\" : \"i would\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"i'm\" : \"i am\",\n",
    "    \"i've\" : \"i have\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"wasn't\" : \"was not\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we'll\" : \"we will\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"y'all\" : \"you all\",\n",
    "}\n",
    "\n",
    "stop_words = {\n",
    "    \"i\", \"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"to\", \n",
    "    \"and\", \"or\", \"but\", \"is\", \"am\", \"are\", \"was\", \n",
    "    \"it\", \"they\", \"this\", \"of\", \"for\", \"with\", \n",
    "    \"as\", \"by\", \"from\", \"that\", \"those\", \"these\",\n",
    "    \n",
    "    \"he\", \"she\", \"we\", \"you\", \"me\", \"him\", \"her\", \n",
    "    \"us\", \"them\", \"my\", \"your\", \"our\", \"their\", \n",
    "    \"do\", \"does\", \"did\", \"have\", \"has\", \"had\", \n",
    "    \"about\", \"above\", \"across\", \"after\", \"against\", \n",
    "    \"along\", \"among\", \"around\", \"behind\", \"below\", \n",
    "    \"beneath\", \"beside\", \"between\", \"beyond\", \n",
    "    \"despite\", \"during\", \"except\", \"into\", \"near\", \n",
    "    \"off\", \"over\", \"past\", \"through\", \"toward\", \n",
    "    \"under\", \"until\", \"up\", \"upon\", \"via\", \"within\", \n",
    "    \"without\", \"although\", \"because\", \"since\", \n",
    "    \"unless\", \"while\", \"where\", \"whether\", \"any\", \n",
    "    \"each\", \"every\", \"either\", \"neither\", \"some\", \n",
    "    \"such\", \"both\", \"few\", \"many\", \"several\", \"all\", \n",
    "    \"other\", \"same\", \"so\", \"too\",\"when\"\n",
    "}\n",
    "\n",
    "negation_words = {\n",
    "    \"not\", \"no\", \"never\", \"none\", \"nobody\", \"nothing\", \"nowhere\",\n",
    "    \"neither\", \"nor\", \"without\", \"cannot\", \"can't\", \"couldn't\",\n",
    "    \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\",\n",
    "    \"isn't\", \"mightn't\", \"mustn't\", \"needn't\", \"oughtn't\", \"shan't\",\n",
    "    \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", \"rarely\",\n",
    "    \"scarcely\", \"hardly\", \"barely\", \"little\", \"few\", \"lack\", \"lacking\",\n",
    "    \"deny\", \"denies\", \"denied\", \"denying\", \"refuse\", \"refuses\",\n",
    "    \"refused\", \"refusing\", \"reject\", \"rejects\", \"rejected\", \"rejecting\"\n",
    "}\n",
    "\n",
    "positive_words = {\n",
    "    \"good\", \"great\", \"excellent\", \"awesome\", \"amazing\", \"wonderful\",\n",
    "    \"fantastic\", \"perfect\", \"outstanding\", \"superb\", \"brilliant\", \"fabulous\",\n",
    "    \"terrific\", \"incredible\", \"lovely\", \"delightful\", \"joyful\", \"happy\",\n",
    "    \"joy\", \"bliss\", \"ecstatic\", \"pleasure\", \"vibrant\", \"optimistic\",\n",
    "    \"positive\", \"success\", \"victory\", \"triumph\", \"peace\", \"harmony\",\n",
    "    \"gratitude\", \"thankful\", \"blessed\", \"lucky\", \"prosperous\", \"rewarding\",\n",
    "    \"satisfying\", \"refreshing\", \"inspiring\", \"motivating\", \"encouraging\",\n",
    "    \"kind\", \"generous\", \"compassionate\", \"honest\", \"trustworthy\", \"loyal\",\n",
    "    \"creative\", \"innovative\", \"energetic\", \"vital\", \"healthy\", \"strong\",\n",
    "    \"courageous\", \"bold\", \"confident\", \"resilient\", \"graceful\", \"elegant\",\n",
    "    \"charming\", \"friendly\", \"welcoming\", \"supportive\", \"helpful\", \"heavenly\",\n",
    "    \"divine\", \"magical\", \"serene\", \"calm\", \"relaxed\", \"bright\", \"shining\",\n",
    "    \"glowing\", \"sparkling\", \"clean\", \"pure\", \"fresh\", \"new\", \"exciting\",\n",
    "    \"thrilling\", \"adventurous\", \"fun\", \"playful\", \"humorous\", \"lighthearted\",\n",
    "    \"smiling\", \"laughing\", \"cheerful\", \"jubilant\", \"celebratory\", \"festive\",\n",
    "    \"colorful\", \"beautiful\", \"stunning\", \"gorgeous\", \"radiant\", \"dazzling\",\n",
    "    \"admire\", \"cherish\", \"treasure\", \"love\", \"adore\", \"passion\", \"devotion\",\"smilingfacewithhearteyes\"\n",
    "}\n",
    "\n",
    "negative_words = {\n",
    "    \"bad\", \"terrible\", \"awful\", \"horrible\", \"worst\", \"disgusting\",\n",
    "    \"hate\", \"loathe\", \"despise\", \"abhor\", \"ugly\", \"painful\",\n",
    "    \"sad\", \"unhappy\", \"miserable\", \"depressed\", \"gloomy\", \"sorrow\",\n",
    "    \"failure\", \"disaster\", \"mess\", \"broken\", \"damaged\", \"defective\",\n",
    "    \"angry\", \"furious\", \"enraged\", \"annoyed\", \"irritated\", \"frustrated\",\n",
    "    \"evil\", \"wicked\", \"cruel\", \"mean\", \"selfish\", \"greedy\", \"corrupt\",\n",
    "    \"harmful\", \"dangerous\", \"toxic\", \"poisonous\", \"deadly\", \"violent\",\n",
    "    \"stupid\", \"idiotic\", \"foolish\", \"ridiculous\", \"nonsense\", \"absurd\",\n",
    "    \"boring\", \"dull\", \"tedious\", \"monotonous\", \"lame\", \"uninteresting\",\n",
    "    \"weak\", \"frail\", \"feeble\", \"helpless\", \"hopeless\", \"useless\",\n",
    "    \"scary\", \"frightening\", \"terrifying\", \"horrifying\", \"creepy\",\n",
    "    \"lonely\", \"isolated\", \"abandoned\", \"rejected\", \"betrayed\", \"ignored\",\n",
    "    \"stress\", \"anxiety\", \"fear\", \"panic\", \"dread\", \"worry\",\n",
    "    \"disappointment\", \"regret\", \"shame\", \"guilt\", \"embarrassment\", \"humiliation\",\n",
    "    \"problem\", \"issue\", \"mistake\", \"error\", \"flaw\", \"defect\",\n",
    "    \"conflict\", \"fight\", \"argument\", \"quarrel\", \"dispute\", \"war\",\n",
    "    \"polluted\", \"dirty\", \"filthy\", \"rotten\", \"decaying\", \"waste\",\n",
    "    \"fake\", \"fraud\", \"lie\", \"cheat\", \"deceive\", \"manipulate\",\n",
    "    \"sick\", \"ill\", \"pain\", \"ache\", \"suffering\", \"agony\",\n",
    "    \"loss\", \"defeat\", \"collapse\", \"crash\", \"bankrupt\", \"ruin\"\n",
    "}\n",
    "\n",
    "positive_emojis = {\n",
    "    \":grinning_face:\", \":beaming_face_with_smiling_eyes:\", \":grinning_face_with_sweat:\",\n",
    "    \":rolling_on_the_floor_laughing:\", \":face_with_tears_of_joy:\", \":smiling_face:\",\n",
    "    \":smiling_face_with_halo:\", \":smiling_face_with_hearts:\", \":smiling_face_with_heart-eyes:\",\n",
    "    \":star-struck:\", \":kissing_face:\", \":kissing_face_with_closed_eyes:\",\n",
    "    \":kissing_face_with_smiling_eyes:\", \":heart_eyes:\", \":face_blowing_a_kiss:\",\n",
    "    \":hugging_face:\", \":thumbs_up:\", \":clapping_hands:\", \":folded_hands:\", \":handshake:\",\n",
    "    \":sparkles:\", \":fire:\", \":rocket:\", \":party_popper:\", \":confetti_ball:\", \":tada:\",\n",
    "    \":balloon:\", \":red_heart:\", \":orange_heart:\", \":yellow_heart:\", \":green_heart:\",\n",
    "    \":blue_heart:\", \":purple_heart:\", \":sparkling_heart:\", \":heart_with_arrow:\",\n",
    "    \":revolving_hearts:\", \":two_hearts:\", \":growing_heart:\", \":heartpulse:\",\n",
    "    \":star:\", \":glowing_star:\", \":sun:\", \":sun_with_face:\", \":rainbow:\", \":flower_playing_cards:\",\n",
    "    \":cherry_blossom:\", \":rose:\", \":hibiscus:\", \":sunflower:\", \":tulip:\", \":bouquet:\",\n",
    "    \":palm_tree:\", \":christmas_tree:\", \":four_leaf_clover:\", \":shamrock:\", \":maple_leaf:\",\n",
    "    \":fallen_leaf:\", \":herb:\", \":potted_plant:\", \":seedling:\", \":crown:\", \":trophy:\",\n",
    "    \":medal:\", \":musical_notes:\", \":musical_note:\", \":party_face:\", \":dancer:\", \":man_dancing:\",\n",
    "    \":woman_dancing:\", \":man_in_tuxedo:\", \":princess:\", \":superhero:\", \":rocket:\", \":airplane:\",\n",
    "    \":checkered_flag:\", \":trophy:\", \":1st_place_medal:\", \":money_with_wings:\", \":dollar_banknote:\",\n",
    "    \":money_bag:\", \":gem_stone:\", \":ring:\", \":gift:\", \":birthday_cake:\", \":champagne:\",\n",
    "    \":clinking_glasses:\", \":beers:\", \":chocolate_bar:\", \":ice_cream:\", \":doughnut:\",\n",
    "    \":cookie:\", \":cake:\", \":pizza:\", \":hamburger:\", \":taco:\", \":burrito:\", \":sushi:\",\n",
    "    \":ramen:\", \":spaghetti:\", \":wine_glass:\", \":hot_beverage:\", \":teacup_without_handle:\",\n",
    "    \":beer_mug:\", \":clinking_beer_mugs:\", \":champagne_glass:\", \":dog_face:\", \":cat_face:\",\n",
    "    \":panda_face:\", \":koala:\", \":unicorn_face:\", \":dragon_face:\", \":dove:\", \":butterfly:\",\n",
    "    \":rainbow_flag:\", \":peace_symbol:\", \":infinity:\", \":recycling_symbol:\", \":white_flower:\",\n",
    "}\n",
    "\n",
    "negative_emojis = {\n",
    "    \":angry_face:\", \":pouting_face:\", \":face_with_symbols_on_mouth:\", \":smiling_face_with_horns:\",\n",
    "    \":angry_face_with_horns:\", \":skull:\", \":skull_and_crossbones:\", \":crying_face:\",\n",
    "    \":loudly_crying_face:\", \":worried_face:\", \":slightly_frowning_face:\", \":confounded_face:\",\n",
    "    \":disappointed_face:\", \":downcast_face:\", \":face_with_steam_from_nose:\", \":face_screaming_in_fear:\",\n",
    "    \":fearful_face:\", \":anxious_face_with_sweat:\", \":sad_but_relieved_face:\", \":sleepy_face:\",\n",
    "    \":tired_face:\", \":yawning_face:\", \":face_with_medical_mask:\", \":nauseated_face:\",\n",
    "    \":face_vomiting:\", \":sneezing_face:\", \":cold_face:\", \":hot_face:\", \":dizzy_face:\",\n",
    "    \":exploding_head:\", \":face_with_head-bandage:\", \":broken_heart:\", \":black_heart:\",\n",
    "    \":thumbs_down:\", \":middle_finger:\", \":raised_fist:\", \":oncoming_fist:\", \":collision:\",\n",
    "    \":bomb:\", \":fire:\", \":dagger:\", \":pistol:\", \":stop_sign:\", \":no_entry:\", \":prohibited:\",\n",
    "    \":warning:\", \":radioactive:\", \":biohazard:\", \":anger_symbol:\", \":hole:\", \":pile_of_poo:\",\n",
    "    \":zombie:\", \":ghost:\", \":japanese_goblin:\", \":japanese_ogre:\", \":clown_face:\",\n",
    "    \":crying_cat_face:\", \":pouting_cat_face:\", \":see-no-evil_monkey:\", \":hear-no-evil_monkey:\",\n",
    "    \":speak-no-evil_monkey:\", \":footprints:\", \":spider:\", \":spider_web:\", \":snake:\", \":rat:\",\n",
    "    \":scorpion:\", \":mosquito:\", \":microbe:\", \":coffin:\", \":funeral_urn:\", \":stopwatch:\",\n",
    "    \":hourglass_done:\", \":hourglass_not_done:\", \":cigarette:\", \":no_smoking:\", \":cactus:\",\n",
    "    \":wilted_flower:\", \":volcano:\", \":earthquake:\", \":tornado:\", \":cloud_with_lightning_and_rain:\",\n",
    "    \":droplet:\", \":sweat_droplets:\", \":dashing_away:\", \":dizzy:\", \":face_with_thermometer:\",\n",
    "    \":sick:\", \":bandage:\", \":syringe:\", \":pill:\", \":test_tube:\", \":magnifying_glass_tilted_left:\",\n",
    "    \":chains:\", \":handcuffs:\", \":locked:\", \":locked_with_key:\", \":locked_with_pen:\"\n",
    "}"
   ],
   "id": "8d20ede368968f58",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Load Data Class",
   "id": "823c2303bd2d8e26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:10:58.019277Z",
     "start_time": "2025-03-09T09:10:58.015380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoder:\n",
    "    def __init__(self,path:str,labels:list[str],shuffle:bool=True):\n",
    "        self.path = path\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def load_data(self)->pd.DataFrame:\n",
    "        data=[]\n",
    "        for label in self.labels:\n",
    "            for filename in glob(f\"{self.path}/{label}/*.txt\"):\n",
    "                with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "                    data.append({\"text\":text,\"label\":label})\n",
    "        if self.shuffle:\n",
    "            random.shuffle(data)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df"
   ],
   "id": "e911f3400e7d0b05",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:11:16.626589Z",
     "start_time": "2025-03-09T09:10:59.799461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_load=DataLoder(\"data/training_data\",labels=[\"neg\",\"pos\"],shuffle=True)\n",
    "sentiment_data=data_load.load_data()\n",
    "sentiment_data.head(5)"
   ],
   "id": "66b9d02e91ec3e73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text label\n",
       "0  the best thing about , \" lake placid \" is that...   neg\n",
       "1  you know you're in for a truly different cinem...   pos\n",
       "2  well i guess it's that time of the year again ...   neg\n",
       "3   \" there's nothing new under the sun \" is a ph...   neg\n",
       "4  synopsis : private detective tom welles is hir...   pos"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the best thing about , \" lake placid \" is that...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know you're in for a truly different cinem...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well i guess it's that time of the year again ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" there's nothing new under the sun \" is a ph...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : private detective tom welles is hir...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Preprocessing Classes",
   "id": "7fa7d13e891dcba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:11:52.901422Z",
     "start_time": "2025-03-09T09:11:52.895974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturesExtractor(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str):\n",
    "        pass\n",
    "\n",
    "class Preprocessing(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str)->str:\n",
    "        pass"
   ],
   "id": "adca4d6675d71963",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:35:41.136182Z",
     "start_time": "2025-03-09T09:35:41.124664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NegationCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in negation_words:\n",
    "                counter+=1\n",
    "        return {\n",
    "            \"neg_word_count\":counter\n",
    "        }\n",
    "\n",
    "class IngCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.endswith(\"ing\"):\n",
    "                counter+=1\n",
    "        return {\"ing_word_count\":counter}\n",
    "\n",
    "class EdCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.endswith(\"ed\"):\n",
    "                counter+=1\n",
    "        return {\"ed_word_count\":counter}\n",
    "\n",
    "class PositiveWordCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in positive_words:\n",
    "                counter+=1\n",
    "        return {\"positive_word_count\":counter}\n",
    "            \n",
    "class NegativeWordsCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in negative_words:\n",
    "                counter+=1\n",
    "        return {\"negative_word_count\":counter}\n",
    "\n",
    "class PositiveEmojiCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=ConvertEmoji().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.startswith(\":\") and token.endswith(\":\") and token in positive_emojis:\n",
    "                counter+=1\n",
    "        return {\"positive_emoji_count\":counter}\n",
    "\n",
    "class NegativeEmojiCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=ConvertEmoji().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.startswith(\":\") and token.endswith(\":\") and token in negative_emojis:\n",
    "                counter+=1\n",
    "        return {\"negative_emoji_count\":counter}\n",
    "\n",
    "class WordCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        return {\"word_count\":len(tokens)}\n",
    "\n",
    "class AverageWordLength(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        tokens_size=len(tokens)\n",
    "        word_sum=0\n",
    "        for token in tokens:\n",
    "            word_sum+=len(token)\n",
    "        avg=word_sum/tokens_size\n",
    "        return {\"avg_word_length\":avg}\n",
    "\n",
    "class UniqueWordRatio(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        word_size=len(tokens)\n",
    "        unique_word_size=len(set(tokens))\n",
    "        ratio=unique_word_size/word_size if word_size > 0 else 0\n",
    "        return {\"unique_word_ratio\":ratio}\n",
    "\n",
    "class ExclamationCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        return {\"exclamation_count\":text.count(\"!\")}\n",
    "\n",
    "class QuestionCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        return {\"question_count\":text.count(\"?\")}\n",
    "\n",
    "class EllipsisCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        ellipsis_count = len(re.findall(r\"\\.\\.\\.\", text))\n",
    "        return {\"ellipsis_count\":ellipsis_count}\n",
    "    \n",
    "class CapitalizedRatio(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        tokens=text.split()\n",
    "        word_size=len(tokens)\n",
    "        capitalized_words = [word for word in tokens if word.isupper() and len(word) > 1]\n",
    "        ratio = len(capitalized_words)/word_size if word_size > 0 else 0\n",
    "        return {\"capitalized_ratio\":ratio}\n",
    "    \n",
    "class RepeatedLettersCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        repeated_letters = re.findall(r'(\\w)\\1{2,}', text)\n",
    "        return {\"repeated_letters_count\":len(repeated_letters)}"
   ],
   "id": "c5f92778e361ba6f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:32:57.290015Z",
     "start_time": "2025-03-09T09:32:57.283057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RemoveSpecialCharacters(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        process_text = re.sub(r\"[^a-zA-Z0-9'\\s]\", '', text)\n",
    "        process_text = re.sub(r\"\\s+\", \" \", process_text)\n",
    "        return process_text\n",
    "\n",
    "class ConvertEmoji(Preprocessing):    \n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        converted_text = emoji.demojize(text)\n",
    "        return converted_text\n",
    "\n",
    "class TextStemmer(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        stemmer=Stemmer.Stemmer(\"english\")\n",
    "        tokens=[stemmer.stemWord(token) for token in tokens]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "class ConvertNumberToWords(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        def replace_match(match):\n",
    "            return num2words(int(match.group(0)), to='ordinal')\n",
    "        return re.sub(r'-?\\d+',replace_match,text)\n",
    "        \n",
    "class NegationHandling(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        tokens=[appos[word] if word in appos else word for word in tokens]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "class RemoveStopWords(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        tokens=[word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)"
   ],
   "id": "f390cd9db0d4c34e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:32:59.850680Z",
     "start_time": "2025-03-09T09:32:59.846666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Pipeline(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str):\n",
    "        pass"
   ],
   "id": "31ea4b85bc31c5ac",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:33:01.174666Z",
     "start_time": "2025-03-09T09:33:01.170107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessingPipeline(Pipeline):\n",
    "    def __init__(self,pipeline_list:list[Preprocessing]):\n",
    "        self.pipeline_list = pipeline_list\n",
    "    \n",
    "    def transform(self,text:str):\n",
    "        for pipeline in self.pipeline_list:\n",
    "            text = pipeline.transform(text)\n",
    "        \n",
    "        return text"
   ],
   "id": "4ca5b76bca440168",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:33:02.763980Z",
     "start_time": "2025-03-09T09:33:02.759943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturesExtractorPipeline(Pipeline):\n",
    "    def __init__(self,pipeline_list:list[FeaturesExtractor]):\n",
    "        self.pipeline_list = pipeline_list\n",
    "    \n",
    "    def transform(self,text:str):\n",
    "        dictionary ={}\n",
    "        for pipeline in self.pipeline_list:\n",
    "            dictionary.update(pipeline.transform(text))\n",
    "        return dictionary            \n",
    "            "
   ],
   "id": "fa6636f36fbd1cec",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:52:26.525377Z",
     "start_time": "2025-03-09T09:52:26.519358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "string=\"100 I love this product! 😍 It's absolutely amazing. But the delivery? was slow... BUT 😠 sooooo\"\n",
    "preprocessing_pipeline=PreprocessingPipeline([\n",
    "    NegationHandling(),\n",
    "    TextStemmer(),\n",
    "    ConvertEmoji(),\n",
    "    RemoveSpecialCharacters(),\n",
    "    ConvertNumberToWords(),\n",
    "    RemoveStopWords()\n",
    "])\n",
    "features_extractor_pipeline=FeaturesExtractorPipeline([\n",
    "    NegationCount(),\n",
    "    IngCount(),\n",
    "    EdCount(),\n",
    "    PositiveWordCount(),\n",
    "    NegativeWordsCount(),\n",
    "    PositiveEmojiCount(),\n",
    "    NegativeEmojiCount(),\n",
    "    WordCount(),\n",
    "    AverageWordLength(),\n",
    "    UniqueWordRatio(),\n",
    "    ExclamationCount(),\n",
    "    QuestionCount(),\n",
    "    EllipsisCount(),\n",
    "    CapitalizedRatio(),\n",
    "    RepeatedLettersCount(),\n",
    "])\n",
    "print(preprocessing_pipeline.transform(string))\n",
    "print(features_extractor_pipeline.transform(string))"
   ],
   "id": "2b056363a2fc80e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hundredth love product smilingfacewithhearteyes absolut amazing delivery slow angryface sooooo\n",
      "{'neg_word_count': 0, 'ing_word_count': 1, 'ed_word_count': 0, 'positive_word_count': 2, 'negative_word_count': 0, 'positive_emoji_count': 1, 'negative_emoji_count': 1, 'word_count': 15, 'avg_word_length': 4.666666666666667, 'unique_word_ratio': 0.9333333333333333, 'exclamation_count': 1, 'question_count': 1, 'ellipsis_count': 1, 'capitalized_ratio': 0.058823529411764705, 'repeated_letters_count': 1}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:42:15.372650Z",
     "start_time": "2025-03-09T09:42:06.695370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(text:str):\n",
    "    features=features_extractor_pipeline.transform(text)\n",
    "    return features\n",
    "\n",
    "expanded=sentiment_data[\"text\"].apply(extract_features).apply(pd.Series)\n",
    "sentiment_data=sentiment_data.join(expanded)\n",
    "sentiment_data.head(5)"
   ],
   "id": "9614d28d969ba702",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text label  neg_word_count  \\\n",
       "0  the best thing about , \" lake placid \" is that...   neg            10.0   \n",
       "1  you know you're in for a truly different cinem...   pos             7.0   \n",
       "2  well i guess it's that time of the year again ...   neg             8.0   \n",
       "3   \" there's nothing new under the sun \" is a ph...   neg            13.0   \n",
       "4  synopsis : private detective tom welles is hir...   pos            12.0   \n",
       "\n",
       "   ing_word_count  ed_word_count  positive_word_count  negative_word_count  \\\n",
       "0             5.0            4.0                  2.0                  2.0   \n",
       "1            18.0           16.0                  5.0                  2.0   \n",
       "2            38.0           14.0                  8.0                  2.0   \n",
       "3            24.0           15.0                  1.0                  3.0   \n",
       "4            30.0           17.0                  5.0                  4.0   \n",
       "\n",
       "   positive_emoji_count  negative_emoji_count  word_count  avg_word_length  \\\n",
       "0                   0.0                   0.0       298.0         4.436242   \n",
       "1                   0.0                   0.0       719.0         4.773296   \n",
       "2                   0.0                   0.0       836.0         4.874402   \n",
       "3                   0.0                   0.0       589.0         4.609508   \n",
       "4                   0.0                   0.0       787.0         4.796696   \n",
       "\n",
       "   unique_word_ratio  exclamation_count  question_count  ellipsis_count  \\\n",
       "0           0.607383                0.0             0.0             0.0   \n",
       "1           0.595271                0.0             1.0             0.0   \n",
       "2           0.545455                2.0             1.0             0.0   \n",
       "3           0.541596                0.0             3.0             0.0   \n",
       "4           0.515883                0.0             1.0             0.0   \n",
       "\n",
       "   capitalized_ratio  repeated_letters_count  \n",
       "0                0.0                     0.0  \n",
       "1                0.0                     0.0  \n",
       "2                0.0                     0.0  \n",
       "3                0.0                     0.0  \n",
       "4                0.0                     0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>ing_word_count</th>\n",
       "      <th>ed_word_count</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>positive_emoji_count</th>\n",
       "      <th>negative_emoji_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>ellipsis_count</th>\n",
       "      <th>capitalized_ratio</th>\n",
       "      <th>repeated_letters_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the best thing about , \" lake placid \" is that...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>4.436242</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know you're in for a truly different cinem...</td>\n",
       "      <td>pos</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>4.773296</td>\n",
       "      <td>0.595271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well i guess it's that time of the year again ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>4.874402</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" there's nothing new under the sun \" is a ph...</td>\n",
       "      <td>neg</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>4.609508</td>\n",
       "      <td>0.541596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : private detective tom welles is hir...</td>\n",
       "      <td>pos</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>4.796696</td>\n",
       "      <td>0.515883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T10:03:33.230836Z",
     "start_time": "2025-03-09T10:03:29.066767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_preprocessing(text:str):\n",
    "    preprocessed_text=preprocessing_pipeline.transform(text)\n",
    "    return preprocessed_text\n",
    "\n",
    "sentiment_data[\"text\"]=sentiment_data[\"text\"].apply(text_preprocessing)\n",
    "sentiment_data.head(5)"
   ],
   "id": "72e9151856c9c471",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text label  neg_word_count  \\\n",
       "0  best thing lake placid onli eightieth minut lo...   neg            10.0   \n",
       "1  know truli differ cinemat experi moment realiz...   pos             7.0   \n",
       "2  well guess time year again one time year movi ...   neg             8.0   \n",
       "3  there noth new sun phrase often use speaker ac...   neg            13.0   \n",
       "4  synopsi privat detect tom well hire wealthi wi...   pos            12.0   \n",
       "\n",
       "   ing_word_count  ed_word_count  positive_word_count  negative_word_count  \\\n",
       "0             5.0            4.0                  2.0                  2.0   \n",
       "1            18.0           16.0                  5.0                  2.0   \n",
       "2            38.0           14.0                  8.0                  2.0   \n",
       "3            24.0           15.0                  1.0                  3.0   \n",
       "4            30.0           17.0                  5.0                  4.0   \n",
       "\n",
       "   positive_emoji_count  negative_emoji_count  word_count  avg_word_length  \\\n",
       "0                   0.0                   0.0       298.0         4.436242   \n",
       "1                   0.0                   0.0       719.0         4.773296   \n",
       "2                   0.0                   0.0       836.0         4.874402   \n",
       "3                   0.0                   0.0       589.0         4.609508   \n",
       "4                   0.0                   0.0       787.0         4.796696   \n",
       "\n",
       "   unique_word_ratio  exclamation_count  question_count  ellipsis_count  \\\n",
       "0           0.607383                0.0             0.0             0.0   \n",
       "1           0.595271                0.0             1.0             0.0   \n",
       "2           0.545455                2.0             1.0             0.0   \n",
       "3           0.541596                0.0             3.0             0.0   \n",
       "4           0.515883                0.0             1.0             0.0   \n",
       "\n",
       "   capitalized_ratio  repeated_letters_count  \n",
       "0                0.0                     0.0  \n",
       "1                0.0                     0.0  \n",
       "2                0.0                     0.0  \n",
       "3                0.0                     0.0  \n",
       "4                0.0                     0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>ing_word_count</th>\n",
       "      <th>ed_word_count</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>positive_emoji_count</th>\n",
       "      <th>negative_emoji_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>ellipsis_count</th>\n",
       "      <th>capitalized_ratio</th>\n",
       "      <th>repeated_letters_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best thing lake placid onli eightieth minut lo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>4.436242</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know truli differ cinemat experi moment realiz...</td>\n",
       "      <td>pos</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>4.773296</td>\n",
       "      <td>0.595271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well guess time year again one time year movi ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>4.874402</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there noth new sun phrase often use speaker ac...</td>\n",
       "      <td>neg</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>4.609508</td>\n",
       "      <td>0.541596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsi privat detect tom well hire wealthi wi...</td>\n",
       "      <td>pos</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>4.796696</td>\n",
       "      <td>0.515883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
