{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T16:55:36.931405Z",
     "start_time": "2025-03-08T16:55:36.226665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import Stemmer\n",
    "import emoji\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "from num2words import num2words"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:37:44.660482Z",
     "start_time": "2025-03-08T20:37:44.647314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "appos = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"how's\" : \"how is\",\n",
    "    \"i'd\" : \"i would\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"i'm\" : \"i am\",\n",
    "    \"i've\" : \"i have\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"wasn't\" : \"was not\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we'll\" : \"we will\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"y'all\" : \"you all\",\n",
    "}\n",
    "\n",
    "stop_words = {\n",
    "    \"i\", \"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"to\", \n",
    "    \"and\", \"or\", \"but\", \"is\", \"am\", \"are\", \"was\", \n",
    "    \"it\", \"they\", \"this\", \"of\", \"for\", \"with\", \n",
    "    \"as\", \"by\", \"from\", \"that\", \"those\", \"these\",\n",
    "    \n",
    "    \"he\", \"she\", \"we\", \"you\", \"me\", \"him\", \"her\", \n",
    "    \"us\", \"them\", \"my\", \"your\", \"our\", \"their\", \n",
    "    \"do\", \"does\", \"did\", \"have\", \"has\", \"had\", \n",
    "    \"about\", \"above\", \"across\", \"after\", \"against\", \n",
    "    \"along\", \"among\", \"around\", \"behind\", \"below\", \n",
    "    \"beneath\", \"beside\", \"between\", \"beyond\", \n",
    "    \"despite\", \"during\", \"except\", \"into\", \"near\", \n",
    "    \"off\", \"over\", \"past\", \"through\", \"toward\", \n",
    "    \"under\", \"until\", \"up\", \"upon\", \"via\", \"within\", \n",
    "    \"without\", \"although\", \"because\", \"since\", \n",
    "    \"unless\", \"while\", \"where\", \"whether\", \"any\", \n",
    "    \"each\", \"every\", \"either\", \"neither\", \"some\", \n",
    "    \"such\", \"both\", \"few\", \"many\", \"several\", \"all\", \n",
    "    \"other\", \"same\", \"so\", \"too\",\"when\"\n",
    "}\n",
    "\n",
    "negation_words = {\n",
    "    \"not\", \"no\", \"never\", \"none\", \"nobody\", \"nothing\", \"nowhere\",\n",
    "    \"neither\", \"nor\", \"without\", \"cannot\", \"can't\", \"couldn't\",\n",
    "    \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\",\n",
    "    \"isn't\", \"mightn't\", \"mustn't\", \"needn't\", \"oughtn't\", \"shan't\",\n",
    "    \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", \"rarely\",\n",
    "    \"scarcely\", \"hardly\", \"barely\", \"little\", \"few\", \"lack\", \"lacking\",\n",
    "    \"deny\", \"denies\", \"denied\", \"denying\", \"refuse\", \"refuses\",\n",
    "    \"refused\", \"refusing\", \"reject\", \"rejects\", \"rejected\", \"rejecting\"\n",
    "}\n",
    "\n",
    "positive_words = {\n",
    "    \"good\", \"great\", \"excellent\", \"awesome\", \"amazing\", \"wonderful\",\n",
    "    \"fantastic\", \"perfect\", \"outstanding\", \"superb\", \"brilliant\", \"fabulous\",\n",
    "    \"terrific\", \"incredible\", \"lovely\", \"delightful\", \"joyful\", \"happy\",\n",
    "    \"joy\", \"bliss\", \"ecstatic\", \"pleasure\", \"vibrant\", \"optimistic\",\n",
    "    \"positive\", \"success\", \"victory\", \"triumph\", \"peace\", \"harmony\",\n",
    "    \"gratitude\", \"thankful\", \"blessed\", \"lucky\", \"prosperous\", \"rewarding\",\n",
    "    \"satisfying\", \"refreshing\", \"inspiring\", \"motivating\", \"encouraging\",\n",
    "    \"kind\", \"generous\", \"compassionate\", \"honest\", \"trustworthy\", \"loyal\",\n",
    "    \"creative\", \"innovative\", \"energetic\", \"vital\", \"healthy\", \"strong\",\n",
    "    \"courageous\", \"bold\", \"confident\", \"resilient\", \"graceful\", \"elegant\",\n",
    "    \"charming\", \"friendly\", \"welcoming\", \"supportive\", \"helpful\", \"heavenly\",\n",
    "    \"divine\", \"magical\", \"serene\", \"calm\", \"relaxed\", \"bright\", \"shining\",\n",
    "    \"glowing\", \"sparkling\", \"clean\", \"pure\", \"fresh\", \"new\", \"exciting\",\n",
    "    \"thrilling\", \"adventurous\", \"fun\", \"playful\", \"humorous\", \"lighthearted\",\n",
    "    \"smiling\", \"laughing\", \"cheerful\", \"jubilant\", \"celebratory\", \"festive\",\n",
    "    \"colorful\", \"beautiful\", \"stunning\", \"gorgeous\", \"radiant\", \"dazzling\",\n",
    "    \"admire\", \"cherish\", \"treasure\", \"love\", \"adore\", \"passion\", \"devotion\",\"smilingfacewithhearteyes\"\n",
    "}\n",
    "\n",
    "negative_words = {\n",
    "    \"bad\", \"terrible\", \"awful\", \"horrible\", \"worst\", \"disgusting\",\n",
    "    \"hate\", \"loathe\", \"despise\", \"abhor\", \"ugly\", \"painful\",\n",
    "    \"sad\", \"unhappy\", \"miserable\", \"depressed\", \"gloomy\", \"sorrow\",\n",
    "    \"failure\", \"disaster\", \"mess\", \"broken\", \"damaged\", \"defective\",\n",
    "    \"angry\", \"furious\", \"enraged\", \"annoyed\", \"irritated\", \"frustrated\",\n",
    "    \"evil\", \"wicked\", \"cruel\", \"mean\", \"selfish\", \"greedy\", \"corrupt\",\n",
    "    \"harmful\", \"dangerous\", \"toxic\", \"poisonous\", \"deadly\", \"violent\",\n",
    "    \"stupid\", \"idiotic\", \"foolish\", \"ridiculous\", \"nonsense\", \"absurd\",\n",
    "    \"boring\", \"dull\", \"tedious\", \"monotonous\", \"lame\", \"uninteresting\",\n",
    "    \"weak\", \"frail\", \"feeble\", \"helpless\", \"hopeless\", \"useless\",\n",
    "    \"scary\", \"frightening\", \"terrifying\", \"horrifying\", \"creepy\",\n",
    "    \"lonely\", \"isolated\", \"abandoned\", \"rejected\", \"betrayed\", \"ignored\",\n",
    "    \"stress\", \"anxiety\", \"fear\", \"panic\", \"dread\", \"worry\",\n",
    "    \"disappointment\", \"regret\", \"shame\", \"guilt\", \"embarrassment\", \"humiliation\",\n",
    "    \"problem\", \"issue\", \"mistake\", \"error\", \"flaw\", \"defect\",\n",
    "    \"conflict\", \"fight\", \"argument\", \"quarrel\", \"dispute\", \"war\",\n",
    "    \"polluted\", \"dirty\", \"filthy\", \"rotten\", \"decaying\", \"waste\",\n",
    "    \"fake\", \"fraud\", \"lie\", \"cheat\", \"deceive\", \"manipulate\",\n",
    "    \"sick\", \"ill\", \"pain\", \"ache\", \"suffering\", \"agony\",\n",
    "    \"loss\", \"defeat\", \"collapse\", \"crash\", \"bankrupt\", \"ruin\"\n",
    "}\n",
    "\n",
    "positive_emojis = {\n",
    "    \":grinning_face:\", \":beaming_face_with_smiling_eyes:\", \":grinning_face_with_sweat:\",\n",
    "    \":rolling_on_the_floor_laughing:\", \":face_with_tears_of_joy:\", \":smiling_face:\",\n",
    "    \":smiling_face_with_halo:\", \":smiling_face_with_hearts:\", \":smiling_face_with_heart-eyes:\",\n",
    "    \":star-struck:\", \":kissing_face:\", \":kissing_face_with_closed_eyes:\",\n",
    "    \":kissing_face_with_smiling_eyes:\", \":heart_eyes:\", \":face_blowing_a_kiss:\",\n",
    "    \":hugging_face:\", \":thumbs_up:\", \":clapping_hands:\", \":folded_hands:\", \":handshake:\",\n",
    "    \":sparkles:\", \":fire:\", \":rocket:\", \":party_popper:\", \":confetti_ball:\", \":tada:\",\n",
    "    \":balloon:\", \":red_heart:\", \":orange_heart:\", \":yellow_heart:\", \":green_heart:\",\n",
    "    \":blue_heart:\", \":purple_heart:\", \":sparkling_heart:\", \":heart_with_arrow:\",\n",
    "    \":revolving_hearts:\", \":two_hearts:\", \":growing_heart:\", \":heartpulse:\",\n",
    "    \":star:\", \":glowing_star:\", \":sun:\", \":sun_with_face:\", \":rainbow:\", \":flower_playing_cards:\",\n",
    "    \":cherry_blossom:\", \":rose:\", \":hibiscus:\", \":sunflower:\", \":tulip:\", \":bouquet:\",\n",
    "    \":palm_tree:\", \":christmas_tree:\", \":four_leaf_clover:\", \":shamrock:\", \":maple_leaf:\",\n",
    "    \":fallen_leaf:\", \":herb:\", \":potted_plant:\", \":seedling:\", \":crown:\", \":trophy:\",\n",
    "    \":medal:\", \":musical_notes:\", \":musical_note:\", \":party_face:\", \":dancer:\", \":man_dancing:\",\n",
    "    \":woman_dancing:\", \":man_in_tuxedo:\", \":princess:\", \":superhero:\", \":rocket:\", \":airplane:\",\n",
    "    \":checkered_flag:\", \":trophy:\", \":1st_place_medal:\", \":money_with_wings:\", \":dollar_banknote:\",\n",
    "    \":money_bag:\", \":gem_stone:\", \":ring:\", \":gift:\", \":birthday_cake:\", \":champagne:\",\n",
    "    \":clinking_glasses:\", \":beers:\", \":chocolate_bar:\", \":ice_cream:\", \":doughnut:\",\n",
    "    \":cookie:\", \":cake:\", \":pizza:\", \":hamburger:\", \":taco:\", \":burrito:\", \":sushi:\",\n",
    "    \":ramen:\", \":spaghetti:\", \":wine_glass:\", \":hot_beverage:\", \":teacup_without_handle:\",\n",
    "    \":beer_mug:\", \":clinking_beer_mugs:\", \":champagne_glass:\", \":dog_face:\", \":cat_face:\",\n",
    "    \":panda_face:\", \":koala:\", \":unicorn_face:\", \":dragon_face:\", \":dove:\", \":butterfly:\",\n",
    "    \":rainbow_flag:\", \":peace_symbol:\", \":infinity:\", \":recycling_symbol:\", \":white_flower:\",\n",
    "}\n",
    "\n",
    "negative_emojis = {\n",
    "    \":angry_face:\", \":pouting_face:\", \":face_with_symbols_on_mouth:\", \":smiling_face_with_horns:\",\n",
    "    \":angry_face_with_horns:\", \":skull:\", \":skull_and_crossbones:\", \":crying_face:\",\n",
    "    \":loudly_crying_face:\", \":worried_face:\", \":slightly_frowning_face:\", \":confounded_face:\",\n",
    "    \":disappointed_face:\", \":downcast_face:\", \":face_with_steam_from_nose:\", \":face_screaming_in_fear:\",\n",
    "    \":fearful_face:\", \":anxious_face_with_sweat:\", \":sad_but_relieved_face:\", \":sleepy_face:\",\n",
    "    \":tired_face:\", \":yawning_face:\", \":face_with_medical_mask:\", \":nauseated_face:\",\n",
    "    \":face_vomiting:\", \":sneezing_face:\", \":cold_face:\", \":hot_face:\", \":dizzy_face:\",\n",
    "    \":exploding_head:\", \":face_with_head-bandage:\", \":broken_heart:\", \":black_heart:\",\n",
    "    \":thumbs_down:\", \":middle_finger:\", \":raised_fist:\", \":oncoming_fist:\", \":collision:\",\n",
    "    \":bomb:\", \":fire:\", \":dagger:\", \":pistol:\", \":stop_sign:\", \":no_entry:\", \":prohibited:\",\n",
    "    \":warning:\", \":radioactive:\", \":biohazard:\", \":anger_symbol:\", \":hole:\", \":pile_of_poo:\",\n",
    "    \":zombie:\", \":ghost:\", \":japanese_goblin:\", \":japanese_ogre:\", \":clown_face:\",\n",
    "    \":crying_cat_face:\", \":pouting_cat_face:\", \":see-no-evil_monkey:\", \":hear-no-evil_monkey:\",\n",
    "    \":speak-no-evil_monkey:\", \":footprints:\", \":spider:\", \":spider_web:\", \":snake:\", \":rat:\",\n",
    "    \":scorpion:\", \":mosquito:\", \":microbe:\", \":coffin:\", \":funeral_urn:\", \":stopwatch:\",\n",
    "    \":hourglass_done:\", \":hourglass_not_done:\", \":cigarette:\", \":no_smoking:\", \":cactus:\",\n",
    "    \":wilted_flower:\", \":volcano:\", \":earthquake:\", \":tornado:\", \":cloud_with_lightning_and_rain:\",\n",
    "    \":droplet:\", \":sweat_droplets:\", \":dashing_away:\", \":dizzy:\", \":face_with_thermometer:\",\n",
    "    \":sick:\", \":bandage:\", \":syringe:\", \":pill:\", \":test_tube:\", \":magnifying_glass_tilted_left:\",\n",
    "    \":chains:\", \":handcuffs:\", \":locked:\", \":locked_with_key:\", \":locked_with_pen:\"\n",
    "}"
   ],
   "id": "8d20ede368968f58",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Load Data Class",
   "id": "823c2303bd2d8e26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:40:33.170604Z",
     "start_time": "2025-03-08T19:40:33.165037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoder:\n",
    "    def __init__(self,path:str,labels:list[str],shuffle:bool=True):\n",
    "        self.path = path\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def load_data(self)->pd.DataFrame:\n",
    "        data=[]\n",
    "        for label in self.labels:\n",
    "            for filename in glob(f\"{self.path}/{label}/*.txt\"):\n",
    "                with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "                    data.append({\"text\":text,\"label\":label})\n",
    "        if self.shuffle:\n",
    "            random.shuffle(data)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df"
   ],
   "id": "e911f3400e7d0b05",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:40:34.920886Z",
     "start_time": "2025-03-08T19:40:34.815370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_load=DataLoder(\"data/training_data\",labels=[\"neg\",\"pos\"],shuffle=True)\n",
    "sentiment_data=data_load.load_data()\n",
    "sentiment_data.head(5)"
   ],
   "id": "66b9d02e91ec3e73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text label\n",
       "0  nicolas cage comes up with an ingenious surviv...   neg\n",
       "1  contact ( pg ) there's a moment late in robert...   pos\n",
       "2  after a rather disappointing \" mary railly \" ,...   pos\n",
       "3  i want to correct what i wrote last year in my...   pos\n",
       "4  when a film is produced on a shoestring budget...   neg"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicolas cage comes up with an ingenious surviv...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contact ( pg ) there's a moment late in robert...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>after a rather disappointing \" mary railly \" ,...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to correct what i wrote last year in my...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when a film is produced on a shoestring budget...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Preprocessing Classes",
   "id": "7fa7d13e891dcba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:51:20.934761Z",
     "start_time": "2025-03-08T19:51:20.930254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturesExtractor(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str):\n",
    "        pass\n",
    "\n",
    "class Preprocessing(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str)->str:\n",
    "        pass"
   ],
   "id": "adca4d6675d71963",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:39:15.427958Z",
     "start_time": "2025-03-08T20:39:15.417607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NegationCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in negation_words:\n",
    "                counter+=1\n",
    "        return {\n",
    "            \"neg_word_count\":counter\n",
    "        }\n",
    "\n",
    "class IngCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.endswith(\"ing\"):\n",
    "                counter+=1\n",
    "        return {\"ing_word_count\":counter}\n",
    "\n",
    "class EdCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.endswith(\"ed\"):\n",
    "                counter+=1\n",
    "        return {\"ed_word_count\":counter}\n",
    "\n",
    "class PositiveWordCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in positive_words:\n",
    "                counter+=1\n",
    "        return {\"positive_word_count\":counter}\n",
    "            \n",
    "class NegativeWordsCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=RemoveSpecialCharacters().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token in negative_words:\n",
    "                counter+=1\n",
    "        return {\"negative_word_count\":counter}\n",
    "\n",
    "class PositiveEmojiCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=ConvertEmoji().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            if token.startswith(\":\") and token.endswith(\":\") and token in positive_emojis:\n",
    "                counter+=1\n",
    "        return {\"positive_emoji_count\":counter}\n",
    "\n",
    "class NegativeEmojiCount(FeaturesExtractor):\n",
    "    def transform(self,text:str):\n",
    "        text=ConvertEmoji().transform(text)\n",
    "        tokens=text.split()\n",
    "        counter=0\n",
    "        for token in tokens:\n",
    "            print(token)\n",
    "            if token.startswith(\":\") and token.endswith(\":\") and token in negative_emojis:\n",
    "                counter+=1\n",
    "        return {\"negative_emoji_count\":counter}\n",
    "                "
   ],
   "id": "c5f92778e361ba6f",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:46:25.327257Z",
     "start_time": "2025-03-08T19:46:25.320694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RemoveSpecialCharacters(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        process_text = re.sub(r\"[^a-zA-Z0-9'\\s]\", '', text)\n",
    "        process_text = re.sub(r\"\\s+\", \" \", process_text)\n",
    "        return process_text\n",
    "\n",
    "class ConvertEmoji(Preprocessing):    \n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        converted_text = emoji.demojize(text)\n",
    "        return converted_text\n",
    "\n",
    "class TextStemmer(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        stemmer=Stemmer.Stemmer(\"english\")\n",
    "        tokens=[stemmer.stemWord(token) for token in tokens]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "class ConvertNumberToWords(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        def replace_match(match):\n",
    "            return num2words(int(match.group(0)), to='ordinal')\n",
    "        return re.sub(r'-?\\d+',replace_match,text)\n",
    "        \n",
    "class NegationHandling(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        tokens=[appos[word] if word in appos else word for word in tokens]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "class RemoveStopWords(Preprocessing):\n",
    "    def transform(self,text:str)->str:\n",
    "        text=text.lower()\n",
    "        tokens=text.split()\n",
    "        tokens=[word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)"
   ],
   "id": "f390cd9db0d4c34e",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:18:35.859649Z",
     "start_time": "2025-03-08T20:18:35.856436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Pipeline(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self,text:str):\n",
    "        pass"
   ],
   "id": "31ea4b85bc31c5ac",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:18:41.476564Z",
     "start_time": "2025-03-08T20:18:41.472350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessingPipeline(Pipeline):\n",
    "    def __init__(self,pipeline_list:list[Preprocessing]):\n",
    "        self.pipeline_list = pipeline_list\n",
    "    \n",
    "    def transform(self,text:str):\n",
    "        for pipeline in self.pipeline_list:\n",
    "            text = pipeline.transform(text)\n",
    "        \n",
    "        return text"
   ],
   "id": "4ca5b76bca440168",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:20:55.481012Z",
     "start_time": "2025-03-08T20:20:55.476976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturesExtractorPipeline(Pipeline):\n",
    "    def __init__(self,pipeline_list:list[FeaturesExtractor]):\n",
    "        self.pipeline_list = pipeline_list\n",
    "    \n",
    "    def transform(self,text:str):\n",
    "        dictionary ={}\n",
    "        for pipeline in self.pipeline_list:\n",
    "            dictionary.update(pipeline.transform(text))\n",
    "        return dictionary            \n",
    "            "
   ],
   "id": "fa6636f36fbd1cec",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T20:39:18.227612Z",
     "start_time": "2025-03-08T20:39:18.223221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "string=\"100 I love this product! üòç It's absolutely amazing. But the delivery was slow... üò†\"\n",
    "pipeline_pre=PreprocessingPipeline([\n",
    "    NegationHandling(),\n",
    "    TextStemmer(),\n",
    "    ConvertEmoji(),\n",
    "    RemoveSpecialCharacters(),\n",
    "    ConvertNumberToWords(),\n",
    "    RemoveStopWords()\n",
    "])\n",
    "pipeline_ext=FeaturesExtractorPipeline([\n",
    "    NegationCount(),\n",
    "    IngCount(),\n",
    "    EdCount(),\n",
    "    PositiveWordCount(),\n",
    "    NegativeWordsCount(),\n",
    "    PositiveEmojiCount(),\n",
    "    NegativeEmojiCount(),\n",
    "])\n",
    "print(pipeline_pre.transform(string))\n",
    "print(pipeline_ext.transform(string))"
   ],
   "id": "2b056363a2fc80e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hundredth love product smilingfacewithhearteyes absolut amazing deliveri slow angryface\n",
      "100\n",
      "i\n",
      "love\n",
      "this\n",
      "product!\n",
      ":smiling_face_with_heart-eyes:\n",
      "it's\n",
      "absolutely\n",
      "amazing.\n",
      "but\n",
      "the\n",
      "delivery\n",
      "was\n",
      "slow...\n",
      ":angry_face:\n",
      "{'neg_word_count': 0, 'ing_word_count': 1, 'ed_word_count': 0, 'positive_word_count': 2, 'negative_word_count': 0, 'positive_emoji_count': 1, 'negative_emoji_count': 1}\n"
     ]
    }
   ],
   "execution_count": 125
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
